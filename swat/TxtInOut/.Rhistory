#start day
mutate(start_day=nday*as.numeric(substr(Start_yr,6,6))/10) %>%
mutate(start_day=replace(start_day,is.na(start_day),1)) %>%
#end day
mutate(end_day=nday*as.numeric(substr(Year,6,6))/10) %>%
mutate(end_day=replace(end_day,is.na(end_day),1)) %>%
#start year
mutate(yr_start=as.numeric(substr(Start_yr,1,4))) %>%
mutate(yr_end=as.numeric(substr(Year,1,4))) %>%
#Start and end dates
mutate(start_date=as.Date(start_day,origin=paste0(yr_start-1,'-12-31'))) %>% # If making the origin the first day of the year it adds 1 day
mutate(end_date=as.Date(end_day,origin=paste0(yr_end-1,'-12-31')))  %>%
mutate(sample_date=as.Date(sample_date, format='%Y%m%d'))%>%
# filter(start_date >= as.Date("2015-05-04")) %>%  # Start of the daily water quality sampling
filter(start_date >= as.Date("2013-01-01")) %>%  # Start of SWAT simulation
mutate(TP_kg_gapFilled=NA,SS_ton_gapFilled=NA)
View(core_data)
View(core_data)
setwd(here('Sediment cores OWC','FROM JORGE'))
core_data<-read.csv('accum_mass.csv')
View(core_data)
# Sample data
date_string <- c("20230719", "20231225", "20240101")
# Convert to date format
date <- as.Date(date_string, format = "%Y%m%d")
# Print the result
print(date)
View(core_data)
as.Date(core_data$sample_date,format='%Y%m%d')
as.Date(as.character(core_data$sample_date),format='%Y%m%d')
core_data <- core_data %>%
filter(!is.na(Start_yr)) %>%
mutate(nday=leap_year(as.numeric(substr(Start_yr,1,4)))*366) %>%
mutate(nday=replace(nday,nday==0,365)) %>%
#start day
mutate(start_day=nday*as.numeric(substr(Start_yr,6,6))/10) %>%
mutate(start_day=replace(start_day,is.na(start_day),1)) %>%
#end day
mutate(end_day=nday*as.numeric(substr(Year,6,6))/10) %>%
mutate(end_day=replace(end_day,is.na(end_day),1)) %>%
#start year
mutate(yr_start=as.numeric(substr(Start_yr,1,4))) %>%
mutate(yr_end=as.numeric(substr(Year,1,4))) %>%
#Start and end dates
mutate(start_date=as.Date(start_day,origin=paste0(yr_start-1,'-12-31'))) %>% # If making the origin the first day of the year it adds 1 day
mutate(end_date=as.Date(end_day,origin=paste0(yr_end-1,'-12-31')))  %>%
mutate(sample_date=as.Date(as.character(sample_date), format='%Y%m%d'))%>%
# filter(start_date >= as.Date("2015-05-04")) %>%  # Start of the daily water quality sampling
filter(start_date >= as.Date("2013-01-01")) %>%  # Start of SWAT simulation
mutate(TP_kg_gapFilled=NA,SS_ton_gapFilled=NA)
View(core_data)
for ( core in c(1:nrow(core_data))){
if (top_of_core %in% core){
core_data$end_date[core]<-core_data$sample_date[core]
}
start_date<-core_data$start_date[core]
end_date<-core_data$end_date[core]
# if it's the top of the sample, use the sample date as the end date
if (!any(duplicated(core_data$Location.depth) & core_data$Location.depth == ind)) {
# If it's the first instance of the index, perform the function
subset_data <- df[df$index_col == index, ]
result <- my_function(subset_data)  # Replace my_function with the actual function you want to apply
}
Summary_load<-BR_obs %>%
select(date,TP_kg_gapFilled,SS_ton_gapFilled) %>%
filter(date >= start_date & date <= end_date) %>%
summarize(TP_kg_gapFilled=sum(TP_kg_gapFilled),
SS_ton_gapFilled=sum(SS_ton_gapFilled))
core_data$TP_kg_gapFilled[core]<-Summary_load$TP_kg_gapFilled
core_data$SS_ton_gapFilled[core]<-Summary_load$SS_ton_gapFilled
i<-i+1
}
# unique sample locations
top_of_core <- match(unique(core_data$Location.depth), core_data$Location.depth)
# unique sample locations
top_of_core <- match(unique(core_data$Location.depth), core_data$Location.depth)
for ( core in c(1:nrow(core_data))){
if (top_of_core %in% core){
core_data$end_date[core]<-core_data$sample_date[core]
}
start_date<-core_data$start_date[core]
end_date<-core_data$end_date[core]
# if it's the top of the sample, use the sample date as the end date
if (!any(duplicated(core_data$Location.depth) & core_data$Location.depth == ind)) {
# If it's the first instance of the index, perform the function
subset_data <- df[df$index_col == index, ]
result <- my_function(subset_data)  # Replace my_function with the actual function you want to apply
}
Summary_load<-BR_obs %>%
select(date,TP_kg_gapFilled,SS_ton_gapFilled) %>%
filter(date >= start_date & date <= end_date) %>%
summarize(TP_kg_gapFilled=sum(TP_kg_gapFilled),
SS_ton_gapFilled=sum(SS_ton_gapFilled))
core_data$TP_kg_gapFilled[core]<-Summary_load$TP_kg_gapFilled
core_data$SS_ton_gapFilled[core]<-Summary_load$SS_ton_gapFilled
i<-i+1
}
top_of_core %in% core
core %in% top_of_core
for ( core in c(1:nrow(core_data))){
if (core %in% top_of_core){
core_data$end_date[core]<-core_data$sample_date[core]
}
start_date<-core_data$start_date[core]
end_date<-core_data$end_date[core]
# if it's the top of the sample, use the sample date as the end date
if (!any(duplicated(core_data$Location.depth) & core_data$Location.depth == ind)) {
# If it's the first instance of the index, perform the function
subset_data <- df[df$index_col == index, ]
result <- my_function(subset_data)  # Replace my_function with the actual function you want to apply
}
Summary_load<-BR_obs %>%
select(date,TP_kg_gapFilled,SS_ton_gapFilled) %>%
filter(date >= start_date & date <= end_date) %>%
summarize(TP_kg_gapFilled=sum(TP_kg_gapFilled),
SS_ton_gapFilled=sum(SS_ton_gapFilled))
core_data$TP_kg_gapFilled[core]<-Summary_load$TP_kg_gapFilled
core_data$SS_ton_gapFilled[core]<-Summary_load$SS_ton_gapFilled
i<-i+1
}
for ( core in c(1:nrow(core_data))){
if (core %in% top_of_core){
core_data$end_date[core]<-core_data$sample_date[core]
}
start_date<-core_data$start_date[core]
end_date<-core_data$end_date[core]
Summary_load<-BR_obs %>%
select(date,TP_kg_gapFilled,SS_ton_gapFilled) %>%
filter(date >= start_date & date <= end_date) %>%
summarize(TP_kg_gapFilled=sum(TP_kg_gapFilled),
SS_ton_gapFilled=sum(SS_ton_gapFilled))
core_data$TP_kg_gapFilled[core]<-Summary_load$TP_kg_gapFilled
core_data$SS_ton_gapFilled[core]<-Summary_load$SS_ton_gapFilled
}
View(core_data)
setwd(here())
write.csv(core_data,'core_data_accumMass.csv',row.names=F)
# Compare core and simulated settling vs in
rm(list=ls())
xlib = c('tidyverse','rstudioapi','here')
lapply(xlib, require, character.only=T) ; rm(xlib)
### read in daily simulated daily res data #####
#########################################################################################
########################## place scenario data here #####################################
#########################################################################################
setwd(dirname(getActiveDocumentContext()$path))  # set wd to current folder script is saved in
#read in folder with data you want to read
tmp <- file(here('FolderName.txt'))
open(tmp, "r") #read
source("~/Margaret A. Davidson Fellowship/Old Woman Creek SWAT/OWC_SWAT_07292021/ParallelLakes/ParallelLakes_decHRUfixDEM/Scenarios/Scripts/SedimentLossChannelvsHRU.R")
View(channel_data)
source("~/Margaret A. Davidson Fellowship/Old Woman Creek SWAT/OWC_SWAT_07292021/ParallelLakes/ParallelLakes_decHRUfixDEM/Scenarios/Scripts/SedimentLossChannelvsHRU.R")
View(sediment_data)
View(channel_data)
View(sediment_data)
View(channel_data)
channel_data<-DF %>%
filter(gis_id<=16)
#read in losses from each HRU type
rm(list=ls())
xlib = c("readtext","dplyr","splitstackshape","stringr","rstudioapi","here","tictoc")
lapply(xlib, require, character.only=T) ; rm(xlib)
set.seed(1)
setwd('C:/Users/kujawa.21/Documents/Margaret A. Davidson Fellowship/Old Woman Creek SWAT/OWC_SWAT_07292021/ParallelLakes/ParallelLakes_decHRUfixDEM/Scenarios/BaselinePlusMgt - ManualCal - NewEXE2/TxtInOut')
#where to save new hru-data file to
ScenarioDir<-getwd()
#########################################################################################
########################## place scenario data here #####################################
#########################################################################################
setwd(dirname(getActiveDocumentContext()$path))  # set wd to current folder script is saved in
#read in folder with data you want to read
tmp <- file(here('FolderName.txt'))
open(tmp, "r") #read
readLines(tmp, n = 1) # format specifications
Folder<-readLines(tmp, n = 1) #Folder with text in out
SaveDir<-readLines(tmp, n = 1) #Folder to save processed outputs to
close(tmp)
Folder<-sub('.*: ', '', Folder) #cut to directory name
SaveDir<-sub('.*: ', '', SaveDir)
#Switch to scenario directory
setwd('..')
Scenario_dir<-paste0(getwd(),"/",Folder,"/TxtInOut") # scenario text in out folder
#Create folder to save in under output folder
#This loop also changes the cd to this folder
Output_dir<-paste0(getwd(),"/","Output","/",SaveDir)
if (dir.exists(Output_dir)) {
setwd(Output_dir)
} else {
dir.create(Output_dir)
setwd(Output_dir)}
#Create folder specifically for Processed  outputs (.csv's)
ProcessedOutput_dir<-paste0(Output_dir,"/ProcessedOutput")
if (dir.exists(ProcessedOutput_dir)) {
setwd(ProcessedOutput_dir)
} else {
dir.create(ProcessedOutput_dir)
setwd(ProcessedOutput_dir)}
############### READ IN nutrient loss DATA ##########################
setwd(Scenario_dir)
tmp <- file('hru_ls_yr.txt')
open(tmp, "r") #read
#read past headerline and save to rewrite the file
topOfFile<-readLines(tmp, n = 3)
#read file
data1<-readLines(tmp, n = -1)
close(tmp)
headers<-c("jday", "mon", "day", "yr", "unit", "gis_id",
"name", "sedyld", "sedorgn", "sedorgp", "surqno3", "lat3no3",  "surqsolp",
"usle",      "sedmin",     "tileno3",     "lchlabp"    ,"tilelabp",      "satexn")
#read by spacing
DF<-strsplit(data1,split=" ")
DF<-lapply(DF, function(z){ z[z != ""]})
DF<-data.frame(do.call(rbind, DF)) #unlist
colnames(DF)<-headers
############### READ IN runoff DATA ##########################
setwd(Scenario_dir)
tmp <- file('hru_wb_yr.txt')
open(tmp, "r") #read
#read past headerline and save to rewrite the file
topOfFile<-readLines(tmp, n = 3)
#read file
data1<-readLines(tmp, n = -1)
close(tmp)
headers<-c("jday", "mon", "day", "yr", "unit", "gis_id",
"name", "precip",     "snofall",      "snomlt", "surq_gen",  "latq", "wateryld", "perc", "et", "ecanopy","eplant",
"esoil",   "surq_cont", "cn",   "sw_init",   "sw_final",      "sw_ave",      "sw_300",
"sno_init",   "sno_final",     "snopack",         "pet",       "qtile",         "irr",  "surq_runon",  "latq_runon", "overbank",
"surq_cha",    "surq_res",     "surq_ls",    "latq_cha",    "latq_res",     "latq_ls",     "gwtranq",       "satex",  "satex_chan",
"sw_change",     "lagsurf",     "laglatq",   "lagsatex" )
#read by spacing
wbyr<-strsplit(data1,split=" ")
wbyr<-lapply(wbyr, function(z){ z[z != ""]})
wbyr<-data.frame(do.call(rbind, wbyr)) #unlist
colnames(wbyr)<-headers
################## READ IN SOILS DATA ###############################
#setwd('..')
#SSURGO<-read.table("SSURGO.txt",header=T,sep="\t")
# currently I only need hydr grp and muid
#SSURGO<-SSURGO[,c(2,6)]
#colnames(hru_data)[5]<-"muid"
#hru_data$muid<-as.integer(hru_data$muid)
#hru_data<-left_join(hru_data,SSURGO,by="muid")
################# READ IN HRU DATA ##################################
##Pull area of each hru from hru.con
##Pull land use from hru-data.hru
tmp <- file('hru-data.hru')
open(tmp, "r") #read
readLines(tmp, n = 2)
data1<-readLines(tmp, n = -1)
#HRUarea<-tibble(substr(HRUarea,11,17),substr(HRUarea,44,50))
#colnames(HRUarea)<-c("name","area_ha")
close(tmp)
headers<-c("id",  "name", "topo", "hydro","soil", "lu_mgt",   "soil_plant_init",  "surf_stor",    "snow", "field" )
#read by spacing
HRUarea<-strsplit(data1,split=" ")
HRUarea<-lapply(HRUarea, function(z){ z[z != ""]})
HRUarea<-data.frame(do.call(rbind, HRUarea)) #unlist
colnames(HRUarea)<-headers
#merge hru params ad hru data to only change hru data
hru_data<-left_join(DF,HRUarea,by=c("name"))
hru_data<-left_join(hru_data,wbyr,by=c("name","jday", "mon", "day", "yr", "unit", "gis_id"))
################# READ IN HRU TOPO ##################################
##Pull area of each hru from hru.con
##Pull land use from hru-data.hru
tmp <- file('topography.hyd')
open(tmp, "r") #read
readLines(tmp, n = 2)
data1<-readLines(tmp, n = -1)
#HRUarea<-tibble(substr(HRUarea,11,17),substr(HRUarea,44,50))
#colnames(HRUarea)<-c("name","area_ha")
close(tmp)
headers<-c("name", "slp", "slp_len",  "lat_len", "dist_cha", "depos" )
#read by spacing
HRUarea<-strsplit(data1,split=" ")
HRUarea<-lapply(HRUarea, function(z){ z[z != ""]})
HRUarea<-data.frame(do.call(rbind, HRUarea)) #unlist
colnames(HRUarea)<-headers
#merge hru params ad hru data to only change hru data
hru_data<-left_join(hru_data,HRUarea[,c(1:2)],by=c("topo"="name"))
################# READ IN HRU AREA ##################################
##Pull area of each hru from hru.con
##Pull land use from hru-data.hru
tmp <- file('hru.con')
open(tmp, "r") #read
readLines(tmp, n = 2)
data1<-readLines(tmp, n = -1)
close(tmp)
#read by spacing
HRUarea<-strsplit(data1,split=" ")
HRUarea<-lapply(HRUarea, function(z){ z[z != ""]})
HRUarea<-data.frame(do.call(rbind, HRUarea)) #unlist
HRUarea<-HRUarea[,c(3:4)]
headers<-c("gis_id", "area")
colnames(HRUarea)<-headers
#merge hru params ad hru data to only change hru data
hru_data<-left_join(hru_data,HRUarea,by=c("gis_id"))
#Find total loss of sediment (tons) from land by multiplying hru_area*sedyld
#sum all years
total_sed_loss<-sum(as.numeric(hru_data$sedyld)*as.numeric(hru_data$area))
####### READ IN CHANNEL DATA #############################################
headers<-c("jday",	"mon",	"day",	"yr",	"unit",	"gis_id",	"name",	"areaha",	"precipha.m",	"evapha.m",
"seepha.m",	"flo_storm.3.s",	"sed_stormtons",	"orgn_storkgN",	"sedp_storkgP",	"no3_storkgN",	"solp_storkgP",
"chla_storkg",	"nh3_storkgN",	"no2_storkgN",	"cbod_storkg",	"dox_storkg",	"san_stortons",	"sil_stortons",	"cla_stortons",	"sag_stortons",
"lag_stortons",	"grv_stortons",	"null1",	"setl_stor","setlp_stor","flo_inm.3.s",	"sed_inmtons",	"orgn_inkgN",	"sedp_inkgP",	"no3_inkgN",
"solp_inkgP",	"chla_inkg",	"nh3_inkgN",	"no2_inkgN",	"cbod_inkg",	"dox_inkg",	"san_intons",	"sil_intons",	"cla_intons",
"sag_intons",	"lag_intons",	"grv_intons",	"null",	"setl_in","setlp_in","flo_outm.3.s",	"sed_outmtons",	"orgn_outkgN",	"sedp_outkgP",	"no3_outkgN",
"solp_outkgP",	"chla_outkg",	"nh3_outkgN",	"no2_outkgN",	"cbod_outkg",	"dox_outkg",	"san_outtons",	"sil_outtons",	"cla_outtons",
"sag_outtons",	"lag_outtons",	"grv_outtons",	"null2","setl_out","setlp_out","water_tempdegC")#"null3","null4","null5","null6","null7")
##### Check if processed channel data already exists
print("reading from channel output")
tmp <- file(here(Scenario_dir,'channel_sd_yr.txt'))
open(tmp, "r") #read
#read past headerlines
readLines(tmp, n = 3)
###### read in simulated data columns #########
#this takes ~23-32 (?) minutes
tic("reading daily data")
data<-readLines(tmp, n = -1)
close(tmp)
DF<-strsplit(data,split=" ")
DF<-lapply(DF, function(z){ z[z != ""]})
DF<-data.frame(do.call(rbind, DF)) #unlist
colnames(DF)<-headers
DF$date<-as.Date(paste(DF$mon,DF$day,DF$yr,sep="/"), format="%m/%d/%Y")              # add date column
DF[,c(1:6,8:(ncol(DF)-1))]<-as.numeric(unlist(DF[,c(1:6,8:(ncol(DF)-1))]))           # convert to numerics
toc()
setwd(ProcessedOutput_dir)
channel_data<-DF %>%
filter(gis_id<=16)
remove(DF)
channel_storage<-sum(as.numeric(channel_data$sed_stormtons))
channel_input<-sum(as.numeric(channel_data$sed_inmtons))
channel_output<-sum(as.numeric(channel_data$sed_outmtons))
channel_in_out<-sum(as.numeric(channel_data$sed_outmtons - channel_data$sed_inmtons))
channel_data$channel_in_out<-as.numeric(channel_data$sed_outmtons - channel_data$sed_inmtons)
View(channel_data)
col_names<-c("HRU loss (tons)","channel input (tons)","channel_output (tons)","channel_storage (tons)","channel sed generated (tons)")
sediment_data<-data.frame(t(c(total_sed_loss,channel_input,channel_output,channel_storage,channel_in_out)))
colnames(sediment_data)<-col_names
View(sediment_data)
View(channel_data)
#read in losses from each HRU type
rm(list=ls())
xlib = c("readtext","dplyr","splitstackshape","stringr","rstudioapi","here","tictoc")
lapply(xlib, require, character.only=T) ; rm(xlib)
set.seed(1)
setwd('C:/Users/kujawa.21/Documents/Margaret A. Davidson Fellowship/Old Woman Creek SWAT/OWC_SWAT_07292021/ParallelLakes/ParallelLakes_decHRUfixDEM/Scenarios/BaselinePlusMgt - ManualCal - NewEXE2/TxtInOut')
#where to save new hru-data file to
ScenarioDir<-getwd()
#########################################################################################
########################## place scenario data here #####################################
#########################################################################################
setwd(dirname(getActiveDocumentContext()$path))  # set wd to current folder script is saved in
#read in folder with data you want to read
tmp <- file(here('FolderName.txt'))
open(tmp, "r") #read
readLines(tmp, n = 1) # format specifications
Folder<-readLines(tmp, n = 1) #Folder with text in out
SaveDir<-readLines(tmp, n = 1) #Folder to save processed outputs to
close(tmp)
Folder<-sub('.*: ', '', Folder) #cut to directory name
SaveDir<-sub('.*: ', '', SaveDir)
#Switch to scenario directory
setwd('..')
Scenario_dir<-paste0(getwd(),"/",Folder,"/TxtInOut") # scenario text in out folder
#Create folder to save in under output folder
#This loop also changes the cd to this folder
Output_dir<-paste0(getwd(),"/","Output","/",SaveDir)
if (dir.exists(Output_dir)) {
setwd(Output_dir)
} else {
dir.create(Output_dir)
setwd(Output_dir)}
#Create folder specifically for Processed  outputs (.csv's)
ProcessedOutput_dir<-paste0(Output_dir,"/ProcessedOutput")
if (dir.exists(ProcessedOutput_dir)) {
setwd(ProcessedOutput_dir)
} else {
dir.create(ProcessedOutput_dir)
setwd(ProcessedOutput_dir)}
############### READ IN nutrient loss DATA ##########################
setwd(Scenario_dir)
tmp <- file('hru_ls_yr.txt')
open(tmp, "r") #read
#read past headerline and save to rewrite the file
topOfFile<-readLines(tmp, n = 3)
#read file
data1<-readLines(tmp, n = -1)
close(tmp)
headers<-c("jday", "mon", "day", "yr", "unit", "gis_id",
"name", "sedyld", "sedorgn", "sedorgp", "surqno3", "lat3no3",  "surqsolp",
"usle",      "sedmin",     "tileno3",     "lchlabp"    ,"tilelabp",      "satexn")
#read by spacing
DF<-strsplit(data1,split=" ")
DF<-lapply(DF, function(z){ z[z != ""]})
DF<-data.frame(do.call(rbind, DF)) #unlist
colnames(DF)<-headers
############### READ IN runoff DATA ##########################
setwd(Scenario_dir)
tmp <- file('hru_wb_yr.txt')
open(tmp, "r") #read
#read past headerline and save to rewrite the file
topOfFile<-readLines(tmp, n = 3)
#read file
data1<-readLines(tmp, n = -1)
close(tmp)
headers<-c("jday", "mon", "day", "yr", "unit", "gis_id",
"name", "precip",     "snofall",      "snomlt", "surq_gen",  "latq", "wateryld", "perc", "et", "ecanopy","eplant",
"esoil",   "surq_cont", "cn",   "sw_init",   "sw_final",      "sw_ave",      "sw_300",
"sno_init",   "sno_final",     "snopack",         "pet",       "qtile",         "irr",  "surq_runon",  "latq_runon", "overbank",
"surq_cha",    "surq_res",     "surq_ls",    "latq_cha",    "latq_res",     "latq_ls",     "gwtranq",       "satex",  "satex_chan",
"sw_change",     "lagsurf",     "laglatq",   "lagsatex" )
#read by spacing
wbyr<-strsplit(data1,split=" ")
wbyr<-lapply(wbyr, function(z){ z[z != ""]})
wbyr<-data.frame(do.call(rbind, wbyr)) #unlist
colnames(wbyr)<-headers
################## READ IN SOILS DATA ###############################
#setwd('..')
#SSURGO<-read.table("SSURGO.txt",header=T,sep="\t")
# currently I only need hydr grp and muid
#SSURGO<-SSURGO[,c(2,6)]
#colnames(hru_data)[5]<-"muid"
#hru_data$muid<-as.integer(hru_data$muid)
#hru_data<-left_join(hru_data,SSURGO,by="muid")
################# READ IN HRU DATA ##################################
##Pull area of each hru from hru.con
##Pull land use from hru-data.hru
tmp <- file('hru-data.hru')
open(tmp, "r") #read
readLines(tmp, n = 2)
data1<-readLines(tmp, n = -1)
#HRUarea<-tibble(substr(HRUarea,11,17),substr(HRUarea,44,50))
#colnames(HRUarea)<-c("name","area_ha")
close(tmp)
headers<-c("id",  "name", "topo", "hydro","soil", "lu_mgt",   "soil_plant_init",  "surf_stor",    "snow", "field" )
#read by spacing
HRUarea<-strsplit(data1,split=" ")
HRUarea<-lapply(HRUarea, function(z){ z[z != ""]})
HRUarea<-data.frame(do.call(rbind, HRUarea)) #unlist
colnames(HRUarea)<-headers
#merge hru params ad hru data to only change hru data
hru_data<-left_join(DF,HRUarea,by=c("name"))
hru_data<-left_join(hru_data,wbyr,by=c("name","jday", "mon", "day", "yr", "unit", "gis_id"))
################# READ IN HRU TOPO ##################################
##Pull area of each hru from hru.con
##Pull land use from hru-data.hru
tmp <- file('topography.hyd')
open(tmp, "r") #read
readLines(tmp, n = 2)
data1<-readLines(tmp, n = -1)
#HRUarea<-tibble(substr(HRUarea,11,17),substr(HRUarea,44,50))
#colnames(HRUarea)<-c("name","area_ha")
close(tmp)
headers<-c("name", "slp", "slp_len",  "lat_len", "dist_cha", "depos" )
#read by spacing
HRUarea<-strsplit(data1,split=" ")
HRUarea<-lapply(HRUarea, function(z){ z[z != ""]})
HRUarea<-data.frame(do.call(rbind, HRUarea)) #unlist
colnames(HRUarea)<-headers
#merge hru params ad hru data to only change hru data
hru_data<-left_join(hru_data,HRUarea[,c(1:2)],by=c("topo"="name"))
################# READ IN HRU AREA ##################################
##Pull area of each hru from hru.con
##Pull land use from hru-data.hru
tmp <- file('hru.con')
open(tmp, "r") #read
readLines(tmp, n = 2)
data1<-readLines(tmp, n = -1)
close(tmp)
#read by spacing
HRUarea<-strsplit(data1,split=" ")
HRUarea<-lapply(HRUarea, function(z){ z[z != ""]})
HRUarea<-data.frame(do.call(rbind, HRUarea)) #unlist
HRUarea<-HRUarea[,c(3:4)]
headers<-c("gis_id", "area")
colnames(HRUarea)<-headers
#merge hru params ad hru data to only change hru data
hru_data<-left_join(hru_data,HRUarea,by=c("gis_id"))
#Find total loss of sediment (tons) from land by multiplying hru_area*sedyld
#sum all years
total_sed_loss<-sum(as.numeric(hru_data$sedyld)*as.numeric(hru_data$area))
####### READ IN CHANNEL DATA #############################################
headers<-c("jday",	"mon",	"day",	"yr",	"unit",	"gis_id",	"name",	"areaha",	"precipha.m",	"evapha.m",
"seepha.m",	"flo_storm.3.s",	"sed_stormtons",	"orgn_storkgN",	"sedp_storkgP",	"no3_storkgN",	"solp_storkgP",
"chla_storkg",	"nh3_storkgN",	"no2_storkgN",	"cbod_storkg",	"dox_storkg",	"san_stortons",	"sil_stortons",	"cla_stortons",	"sag_stortons",
"lag_stortons",	"grv_stortons",	"null1",	"setl_stor","setlp_stor","flo_inm.3.s",	"sed_inmtons",	"orgn_inkgN",	"sedp_inkgP",	"no3_inkgN",
"solp_inkgP",	"chla_inkg",	"nh3_inkgN",	"no2_inkgN",	"cbod_inkg",	"dox_inkg",	"san_intons",	"sil_intons",	"cla_intons",
"sag_intons",	"lag_intons",	"grv_intons",	"null",	"setl_in","setlp_in","flo_outm.3.s",	"sed_outmtons",	"orgn_outkgN",	"sedp_outkgP",	"no3_outkgN",
"solp_outkgP",	"chla_outkg",	"nh3_outkgN",	"no2_outkgN",	"cbod_outkg",	"dox_outkg",	"san_outtons",	"sil_outtons",	"cla_outtons",
"sag_outtons",	"lag_outtons",	"grv_outtons",	"null2","setl_out","setlp_out","water_tempdegC")#"null3","null4","null5","null6","null7")
##### Check if processed channel data already exists
print("reading from channel output")
tmp <- file(here(Scenario_dir,'channel_sd_yr.txt'))
open(tmp, "r") #read
#read past headerlines
readLines(tmp, n = 3)
###### read in simulated data columns #########
#this takes ~23-32 (?) minutes
tic("reading daily data")
data<-readLines(tmp, n = -1)
close(tmp)
DF<-strsplit(data,split=" ")
DF<-lapply(DF, function(z){ z[z != ""]})
DF<-data.frame(do.call(rbind, DF)) #unlist
colnames(DF)<-headers
DF$date<-as.Date(paste(DF$mon,DF$day,DF$yr,sep="/"), format="%m/%d/%Y")              # add date column
DF[,c(1:6,8:(ncol(DF)-1))]<-as.numeric(unlist(DF[,c(1:6,8:(ncol(DF)-1))]))           # convert to numerics
toc()
View(DF)
source("~/Margaret A. Davidson Fellowship/Old Woman Creek SWAT/OWC_SWAT_07292021/ParallelLakes/ParallelLakes_decHRUfixDEM/Scenarios/Scripts/EditChannelParams_newSWAT.R")
source("~/Margaret A. Davidson Fellowship/Old Woman Creek SWAT/OWC_SWAT_07292021/ParallelLakes/ParallelLakes_decHRUfixDEM/Scenarios/Scripts/EditChannelParams_newSWAT.R")
